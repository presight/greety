[FaceRepresentation]
aligned_images = ./generated/aligned
normalized_images = ./generated/normalized

[FaceDetection]
# What face detector lib to use, could be dlib or opencv. Dlib face detection is slow but very acurate, while opencv face detection is fast but generate many false positives.
detector = dlib

# How much two face detected squares have to intersect each other in order for them to be classified as belonging to the same face. Used for tracking already identified faces.
intersect_threshold = 0.9

## OpenCV ##
# Path to the opencv cascade file for identifying faces.
cascade = /usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml

# Min size (in pixels) of a identified face. Those below the threshold will be ignored.
min_box_size = 25,25

# Read more about scale_factor and min_neighbours at
# http://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html#cascadeclassifier-detectmultiscale 
scale_factor = 1.1
min_neighbours = 3

[Embedding]
# Dlib predictor to use.
predictor = ./openface/models/dlib/shape_predictor_68_face_landmarks.dat

# Torch model for generating face representations.
model = ./openface/models/openface/nn4.small2.v1.t7

# Dimension (in pixels) of the faces. If this is changed we also need to change the torch_model.
image_dim = 96

[Video]
# Show the video with identified faces marked. Turn off this for higher performance.
show_video = True

# Rotate the video capture, in case the camera has a different orientation.
rotate_video = 0

# Camera device to use. Most likeley you want to use device 0, but if there are more than one camera this might need to be changed.
device = 0

# Size (in pixels) of the video. Higher size give higher resolution of the face images to classify, but result in slower performance.
image_size = 640,480

# Save faces images that greety is unable to identify. These images are aligned and can then be put in ./generated/aligned/ to use when training the classifier to identify new people or faces.
save_unknown = False

[Identification]
# Min confidence of the classifier in order to identify a face. When changing the parameters in train.py this will most likeley need to be changed.
min_confidence = 0.998

# Face identification classifier to use.
classifier = ./generated/classifier.pkl

[Greetings]
# Language to use in text to speech.
language = sv

# How long (in seconds) to wait between playing welcome messages.
message_wait_time = 60

# English messages.
messages = {
    "en": [
    	  "Hello {name}, how are you today?",
    	  "Oh, is it you again {name}?",
    	  "Hi there {name}! You're awesome and you know it.",
    	  "{name}, is it you?",
    	  "All rise for {name}!"],
    "sv": [
    	  "Hej {name}, vad händer?",
    	  "Välkommen {name}!",
    	  "Hej, vad kul att se dig igen {name}!",
    	  "Vem där? Är det du {name}?",
    	  "Godmorgon {name}, hur ska du rädda världen idag?",
    	  "Tja {name}, läget?"]}

# Text to speech api to use, currently you can choose between espeak and marytts.
speech_api = espeak

[Performance]
# How many frames to skip before doing face detection again. Face detection in dlib is very expensive compared to opencv. 
skip_frames = 3

[Training]
# Location of the labels data containing label, image pairs.
labels_data = ./generated/labels.csv

# Location of the reps_data containing face embeddings.
reps_data = ./generated/reps.csv

# Location of the generated unknown face reps file. Comment out the line or set to None if you don't want unknown reps.
unknown_reps = ./generated/unknown.npy

# How large percentage of the data set should be used for testing.
test_size = 0.4

# Classificator to use for training. Can be DBN or GuassianNB.
classificator = DBN

# Parameters for DBN, read more at https://github.com/dnouri/nolearn/blob/master/nolearn/dbn.py
dbn_learn_rates = 0.005
dbn_learn_rate_decays = 1
dbn_epochs = 500
dbn_minibatch_size = 6
dbn_verbose = 0
dbn_dropouts = 0.15
dbn_hidden_dim = 24

# Use cross validation to train and evaluate the classificator.
cross_validate = True

# Evaluate the classificator and print the results.
evaluate_result = True

# Useful when finetuning the training parameters to get the same random seed every time. Set to None or comment out to get a random state every time.
random_state = 0