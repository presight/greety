[FaceDetection]
# What face detector lib to use, could be dlib or opencv. Dlib face detection is slow but very acurate, while opencv face detection is fast but generate many false positives.
detector = dlib

# How much two face detected squares have to intersect each other in order for them to be classified as belonging to the same face. Used for tracking already identified faces.
intersect_threshold = 0.9

## OpenCV ##
# Path to the opencv cascade file for identifying faces.
cascade = /usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml

# Min size (in pixels) of a identified face. Those below the threshold will be ignored.
min_box_size = 25,25

# Read more about scale_factor and min_neighbours at
# http://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html#cascadeclassifier-detectmultiscale 
scale_factor = 1.1
min_neighbours = 3

[Embedding]
# Dlib predictor to use.
predictor = ./openface/models/dlib/shape_predictor_68_face_landmarks.dat

# Torch model for generating face representations.
model = ./openface/models/openface/nn4.small2.v1.t7

# Dimension (in pixels) of the faces. If this is changed we also need to change the torch_model.
image_dim = 96

[Video]
# Show the video with identified faces marked. Turn off this for higher performance.
show_video = True

# Rotate the video capture, in case the camera has a different orientation
rotate_video = 0

# Camera device to use. Most likeley you want to use device 0, but if there are more than one camera this might need to be changed.
device = 1

# Size (in pixels) of the video. Higher size give higher resolution of the face images to classify, but result in slower performance.
image_size = 640,480

# Save faces images that greety is unable to identify. These images are aligned and can then be put in ./generated/aligned/ to use when training the classifier to identify new people or faces.
save_unknown = True

[Identification]
# Min confidence of the classifier in order to identify a face. When changing the parameters in train.py this will most likeley need to be changed.
min_confidence = 0.999

# Face identification classifier to use
classifier = ./generated/classifier.pkl

[Greetings]
# Language to use in text to speach
language = sv

# How long (in seconds) to wait between playing welcome messages
message_wait_time = 60

# English messages
messages = {
    "en": [
    	  "Hello {name}, how are you today?",
    	  "Oh, is it you again {name}?",
    	  "Hi there {name}! You're awesome and you know it.",
    	  "{name}, is it you?",
    	  "All rise for {name}!"],
    "sv": [
    	  "Hej {name}, vad händer?",
    	  "Välkommen {name}!",
    	  "Hej, vad kul att se dig igen {name}!",
    	  "Vem där? Är det du {name}?",
    	  "Godmorgon {name}, hur ska du rädda världen idag?",
    	  "Tja {name}, läget?"]}

# Text to speech api to use, currently you can choose between espeak and marytts
speech_api = espeak

[Performance]
# How many frames to skip before doing face detection again. Face detection in dlib is very expensive compared to opencv. 
skip_frames = 3
